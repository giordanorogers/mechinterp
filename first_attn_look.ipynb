{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-27 04:33:27 __main__ INFO     torch.__version__='2.7.1+cu126', torch.version.cuda='12.6'\n",
      "2025-06-27 04:33:27 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-06-27 04:33:27 __main__ INFO     transformers.__version__='4.53.0'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.embed_tokens': 7,\n",
       " 'model.norm': 7,\n",
       " 'model.rotary_emb': 7,\n",
       " 'lm_head': 7,\n",
       " 'model.layers.0': 0,\n",
       " 'model.layers.1': 1,\n",
       " 'model.layers.2': 2,\n",
       " 'model.layers.3': 3,\n",
       " 'model.layers.4': 4,\n",
       " 'model.layers.5': 5,\n",
       " 'model.layers.6': 6,\n",
       " 'model.layers.7': 7,\n",
       " 'model.layers.8': 0,\n",
       " 'model.layers.9': 1,\n",
       " 'model.layers.10': 2,\n",
       " 'model.layers.11': 3,\n",
       " 'model.layers.12': 4,\n",
       " 'model.layers.13': 5,\n",
       " 'model.layers.14': 6,\n",
       " 'model.layers.15': 7,\n",
       " 'model.layers.16': 0,\n",
       " 'model.layers.17': 1,\n",
       " 'model.layers.18': 2,\n",
       " 'model.layers.19': 3,\n",
       " 'model.layers.20': 4,\n",
       " 'model.layers.21': 5,\n",
       " 'model.layers.22': 6,\n",
       " 'model.layers.23': 7,\n",
       " 'model.layers.24': 0,\n",
       " 'model.layers.25': 1,\n",
       " 'model.layers.26': 2,\n",
       " 'model.layers.27': 3,\n",
       " 'model.layers.28': 4,\n",
       " 'model.layers.29': 5,\n",
       " 'model.layers.30': 6,\n",
       " 'model.layers.31': 7,\n",
       " 'model.layers.32': 0,\n",
       " 'model.layers.33': 1,\n",
       " 'model.layers.34': 2,\n",
       " 'model.layers.35': 3,\n",
       " 'model.layers.36': 4,\n",
       " 'model.layers.37': 5,\n",
       " 'model.layers.38': 6,\n",
       " 'model.layers.39': 7,\n",
       " 'model.layers.40': 0,\n",
       " 'model.layers.41': 1,\n",
       " 'model.layers.42': 2,\n",
       " 'model.layers.43': 3,\n",
       " 'model.layers.44': 4,\n",
       " 'model.layers.45': 5,\n",
       " 'model.layers.46': 6,\n",
       " 'model.layers.47': 7,\n",
       " 'model.layers.48': 0,\n",
       " 'model.layers.49': 1,\n",
       " 'model.layers.50': 2,\n",
       " 'model.layers.51': 3,\n",
       " 'model.layers.52': 4,\n",
       " 'model.layers.53': 5,\n",
       " 'model.layers.54': 6,\n",
       " 'model.layers.55': 7,\n",
       " 'model.layers.56': 0,\n",
       " 'model.layers.57': 1,\n",
       " 'model.layers.58': 2,\n",
       " 'model.layers.59': 3,\n",
       " 'model.layers.60': 4,\n",
       " 'model.layers.61': 5,\n",
       " 'model.layers.62': 6,\n",
       " 'model.layers.63': 7,\n",
       " 'model.layers.64': 0,\n",
       " 'model.layers.65': 1,\n",
       " 'model.layers.66': 2,\n",
       " 'model.layers.67': 3,\n",
       " 'model.layers.68': 4,\n",
       " 'model.layers.69': 5,\n",
       " 'model.layers.70': 6,\n",
       " 'model.layers.71': 7,\n",
       " 'model.layers.72': 0,\n",
       " 'model.layers.73': 1,\n",
       " 'model.layers.74': 2,\n",
       " 'model.layers.75': 3,\n",
       " 'model.layers.76': 4,\n",
       " 'model.layers.77': 5,\n",
       " 'model.layers.78': 6,\n",
       " 'model.layers.79': 7}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "device_map = get_device_map(model_key, 32, n_gpus=8)\n",
    "device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/disk/u/gio/mechinterp'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8baf8d2bbce462285f1720e1d8c3688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-27 04:35:25 src.models INFO     loaded model <models/meta-llama/Llama-3.3-70B-Instruct> | size: 134570.516 MB | dtype: torch.bfloat16 | device: cuda:7\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from typing import Literal\n",
    "#from src.probing.prompt import ProbingPrompt\n",
    "#from src.hooking.llama_attention import AttentionEdge\n",
    "#\n",
    "#def get_edges_to_be_ablated(\n",
    "#    prompt: ProbingPrompt,\n",
    "#    focus_strategy: Literal[\"entities\", \"entities_last\", \"ablate_all\"] = \"ablate_all\",\n",
    "#    Q_IDX: int = -1, # almost always the last token position\n",
    "#    whitelist_key_indices: list[int] = [0, -1],\n",
    "#):\n",
    "#    \"\"\"\n",
    "#    For attention ablation experiments.\n",
    "#    Determines which attention connections should be blocked (ablated) between tokens.\n",
    "#    Used to understand which attention patterns are important for specific model behaviors.\n",
    "#\n",
    "#    Creates a block list of attention edges by:\n",
    "#        1. Converting negative indices to positive ones\n",
    "#        2. Building a whitelist of key positions to preserve based on the strategy\n",
    "#        3. Creating AttentionEdge objects for all non-whitelisted positions\n",
    "#\n",
    "#    Whitelisting strategy: Instead of specifying which edge to ablate, specify which connections\n",
    "#        to preserve, and everything else gets ablated.\n",
    "#\n",
    "#    Arguments:\n",
    "#        focus_strategy: controls which entity-related tokens to preserve\n",
    "#            entities: keeps all tokens within both entity ranges\n",
    "#            entities_last: only keeps the last token of each entity\n",
    "#            ablate_all: no special entity preservation\n",
    "#        Q_IDX: the query token position (usually the last token where we want to measure the effect)\n",
    "#        whitelist_key_indices: additional key positions to preserve (defaults to first and last tokens)\n",
    "#\n",
    "#    Returns:\n",
    "#        AttentionEdge: represent specific attention connections from a query token position\n",
    "#            to key token positions that should be blocked.\n",
    "#    \"\"\"\n",
    "#    for idx, ti in enumerate(whitelist_key_indices):\n",
    "#        if ti < 0:\n",
    "#            whitelist_key_indices[idx] = prompt.tokenized[\"input_ids\"][0].shape[-1] + ti\n",
    "#    \n",
    "#    if focus_strategy == \"entities\":\n",
    "#        whitelist_key_indices += list(range(*prompt.entity_ranges[0])) + list(\n",
    "#            range(*prompt.entity_ranges[1])\n",
    "#        )\n",
    "#    elif focus_strategy == \"entities_last\":\n",
    "#        whitelist_key_indices += [\n",
    "#            prompt.entity_ranges[0][1] - 1,\n",
    "#            prompt.entity_ranges[1][1] - 1,\n",
    "#        ]\n",
    "#    elif focus_strategy == \"ablate_all\":\n",
    "#        pass\n",
    "#    else:\n",
    "#        raise ValueError(f\"{focus_strategy=}\")\n",
    "#\n",
    "#    whitelist_key_indices = list(set(whitelist_key_indices))\n",
    "#    if Q_IDX < 0:\n",
    "#        Q_IDX = prompt.tokenized[\"input_ids\"][0].shape[-1] + Q_IDX\n",
    "#\n",
    "#    block_edges: list[AttentionEdge] = []\n",
    "#    for k_idx in range(0, prompt.tokenized[\"input_ids\"][0].shape[-1]):\n",
    "#        if k_idx in whitelist_key_indices:\n",
    "#            continue\n",
    "#        block_edges.append(\n",
    "#            AttentionEdge(\n",
    "#                q_idx=Q_IDX,\n",
    "#                k_idx=k_idx,\n",
    "#            )\n",
    "#        )\n",
    "#\n",
    "#    return block_edges\n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(os.path.join(env_utils.DEFAULT_DATA_DIR, \"coincidences_sample.json\")) as f:\n",
    "#    coincidences = json.load(f)\n",
    "#\n",
    "#logger.info(f\"{len(coincidences['examples'])=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from typing import Literal\n",
    "#from src.probing.prompt import prepare_probing_input\n",
    "#from src.functional import predict_next_token\n",
    "#from src.tokens import TokenizerOutput\n",
    "#\n",
    "#focus_strategy: Literal[\"entities\", \"entities_last\", \"ablate_all\"] = \"entities\"\n",
    "#\n",
    "#effects = []\n",
    "#\n",
    "#for idx, c in enumerate(coincidences[\"examples\"]):\n",
    "#    entities = c[\"entity_pair\"]\n",
    "#    logger.info(f\"({idx + 1}/{len(coincidences['examples'])})  {entities=}\")\n",
    "#\n",
    "#    prompt = prepare_probing_input(\n",
    "#        mt=mt,\n",
    "#        entities=entities,\n",
    "#        #prefix=prefix,\n",
    "#        #answer_marker=answer_marker,\n",
    "#        #question_marker=question_marker,\n",
    "#        #block_separator=block_separator,\n",
    "#        answer_prefix=\" They are/were both\",\n",
    "#    )\n",
    "#\n",
    "#    logger.info(f\"{prompt=}\")\n",
    "#\n",
    "#    clean_answer = predict_next_token(\n",
    "#        mt=mt, inputs=TokenizerOutput(data=prompt.tokenized), k=1\n",
    "#    )[0][0]\n",
    "#    logger.info(f\"{clean_answer=}\")\n",
    "#\n",
    "#    block_edges = get_edges_to_be_ablated(\n",
    "#        prompt=prompt,\n",
    "#        focus_strategy=focus_strategy,\n",
    "#        Q_IDX=-2,\n",
    "#        whitelist_key_indices=[0]\n",
    "#    )\n",
    "#\n",
    "#    logger.info(f\"{block_edges=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patching from a different run to check contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.probing.prompt import BiAssociationPrefix\n",
    "#from src.utils.experiment_utils import set_seed\n",
    "#\n",
    "#prefix_generator_cls = BiAssociationPrefix\n",
    "#\n",
    "#set_seed(9001)\n",
    "#\n",
    "#prefix_generator = prefix_generator_cls(\n",
    "#    filter_attributes=[\"nationality\", \"profession\", \"school\"],\n",
    "#    format=\"_3\"\n",
    "#)\n",
    "#\n",
    "#prefix = prefix_generator.get_prefix(\n",
    "#    n_valid=10,\n",
    "#    n_none=1\n",
    "#)\n",
    "#print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared attribute] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person Y and Person Z\n",
      "A: No - Person Y and Person Z have nothing in common.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n"
     ]
    }
   ],
   "source": [
    "from src.probing.prompt import BiAssociationPrefix\n",
    "from src.utils.experiment_utils import set_seed\n",
    "from src.probing.few_shot_examples import (\n",
    "    human_nationality,\n",
    "    human_profession,\n",
    "    human_alma_mater\n",
    ")\n",
    "\n",
    "prefix_generator_cls = BiAssociationPrefix\n",
    "\n",
    "prefix_generator = prefix_generator_cls(\n",
    "    filter_attributes=[\n",
    "        \"nationality\",\n",
    "        \"profession\",\n",
    "        \"school\"\n",
    "    ],\n",
    "    format = \"_3\"\n",
    ")\n",
    "\n",
    "set_seed(9001)\n",
    "prefix = prefix_generator.get_prefix()\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.tokens import align_patching_positions, find_token_range\n",
    "#\n",
    "#aligned_prompts = align_patching_positions(\n",
    "#    mt=mt,\n",
    "#    prompt_template=sample.prompt_template,\n",
    "#    clean_subj=sample.clean_entity,\n",
    "#    patched_subj=sample.patched_entity,\n",
    "#    trace_start_marker=prefix_generator.question_marker,\n",
    "#)\n",
    "#\n",
    "#aligned_prompts[\"subj_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 20 samples:\n",
      "\n",
      "Sample 1:\n",
      "  Prompt Template: # Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n",
      "\n",
      "Q: {} and Grace Wanjiru\n",
      "A: Yes -\n",
      "  Common Entity: Grace Wanjiru\n",
      "  Clean Entity: James Mwangi\n",
      "  Clean Answer: Ken\n",
      "  Patched Entity: Fatima Sheikh\n",
      "  Patched Answer: Urban\n",
      "  Patched Answer Token: [94368]\n",
      "  String representation: Grace Wanjiru | James Mwangi => \"Ken\" | <-- | Fatima Sheikh => \"Urban\"\n",
      "\n",
      "Sample 2:\n",
      "  Prompt Template: # Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n",
      "\n",
      "Q: {} and Rahman Ali\n",
      "A: Yes -\n",
      "  Common Entity: Rahman Ali\n",
      "  Clean Entity: Nasreen Begum\n",
      "  Clean Answer: Bang\n",
      "  Patched Entity: Takeshi Yamamoto\n",
      "  Patched Answer: Civil\n",
      "  Patched Answer Token: [68926]\n",
      "  String representation: Rahman Ali | Nasreen Begum => \"Bang\" | <-- | Takeshi Yamamoto => \"Civil\"\n",
      "\n",
      "Sample 3:\n",
      "  Prompt Template: # Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n",
      "\n",
      "Q: {} and Takeshi Yamamoto\n",
      "A: Yes -\n",
      "  Common Entity: Takeshi Yamamoto\n",
      "  Clean Entity: Yuki Tanaka\n",
      "  Clean Answer: Japanese\n",
      "  Patched Entity: Rahman Ali\n",
      "  Patched Answer: Civil\n",
      "  Patched Answer Token: [68926]\n",
      "  String representation: Takeshi Yamamoto | Yuki Tanaka => \"Japanese\" | <-- | Rahman Ali => \"Civil\"\n",
      "\n",
      "Sample 4:\n",
      "  Prompt Template: # Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n",
      "\n",
      "Q: {} and Anna Schmidt\n",
      "A: Yes -\n",
      "  Common Entity: Anna Schmidt\n",
      "  Clean Entity: Hans Mueller\n",
      "  Clean Answer: German\n",
      "  Patched Entity: Yuki Tanaka\n",
      "  Patched Answer: Marketing\n",
      "  Patched Answer Token: [68662]\n",
      "  String representation: Anna Schmidt | Hans Mueller => \"German\" | <-- | Yuki Tanaka => \"Marketing\"\n",
      "\n",
      "Sample 5:\n",
      "  Prompt Template: # Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n",
      "\n",
      "Q: {} and Yuki Tanaka\n",
      "A: Yes -\n",
      "  Common Entity: Yuki Tanaka\n",
      "  Clean Entity: Takeshi Yamamoto\n",
      "  Clean Answer: Japanese\n",
      "  Patched Entity: Anna Schmidt\n",
      "  Patched Answer: Marketing\n",
      "  Patched Answer Token: [68662]\n",
      "  String representation: Yuki Tanaka | Takeshi Yamamoto => \"Japanese\" | <-- | Anna Schmidt => \"Marketing\"\n",
      "\n",
      "\n",
      "JSON representation of first sample:\n",
      "{\n",
      "  \"prompt_template\": \"# Task: Find Common Attributes Between Two People\\nYou will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\\n\\n## Response Format:\\n- If you find a match: \\\"Yes - [shared entity] - [description of what they share]\\\"\\n- If no match: \\\"No - [Person 1] and [Person 2] have nothing in common\\\"\\n\\n## Attributes to Consider:\\n1. Same nationality \\u2192 \\\"Yes - [nationality] - they are both [nationality]\\\"\\n2. Same profession \\u2192 \\\"Yes - [profession] - they are both [profession]\\\"\\n3. Same school \\u2192 \\\"Yes - [school] - they both graduated from [school]\\\"\\n\\nQ: Person W and Person X\\nA: No - Person W and Person X have nothing in common.\\n\\nQ: Person E and Person F\\nA: Yes - Boston University - they both graduated from Boston University.\\n\\nQ: Person C and Person D\\nA: Yes - Doctor - they are both doctors.\\n\\nQ: Person A and Person B\\nA: Yes - German - they are both German.\\n\\n## Your turn, give your answer in a single line.\\n\\nQ: {} and Grace Wanjiru\\nA: Yes -\",\n",
      "  \"common_entity\": \"Grace Wanjiru\",\n",
      "  \"clean_entity\": \"James Mwangi\",\n",
      "  \"patched_entity\": \"Fatima Sheikh\",\n",
      "  \"clean_answer\": \"Ken\",\n",
      "  \"patched_answer\": \"Urban\",\n",
      "  \"patched_answer_toks\": [\n",
      "    94368\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import Optional, List\n",
    "from src.dataset import ActivationPatchingSamples\n",
    "\n",
    "def create_prompt_template(common_entity: str) -> str:\n",
    "    \"\"\"\n",
    "    Create the prompt template with the common entity inserted.\n",
    "    \"\"\"\n",
    "    template = f\"\"\"# Task: Find Common Attributes Between Two People\n",
    "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
    "\n",
    "## Response Format:\n",
    "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
    "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
    "\n",
    "## Attributes to Consider:\n",
    "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
    "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
    "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
    "\n",
    "Q: Person W and Person X\n",
    "A: No - Person W and Person X have nothing in common.\n",
    "\n",
    "Q: Person E and Person F\n",
    "A: Yes - Boston University - they both graduated from Boston University.\n",
    "\n",
    "Q: Person C and Person D\n",
    "A: Yes - Doctor - they are both doctors.\n",
    "\n",
    "Q: Person A and Person B\n",
    "A: Yes - German - they are both German.\n",
    "\n",
    "## Your turn, give your answer in a single line.\n",
    "\n",
    "Q: {{}} and {common_entity}\n",
    "A: Yes -\"\"\"\n",
    "    \n",
    "    return template\n",
    "\n",
    "def parse_activation_data(data_string: str) -> List[ActivationPatchingSamples]:\n",
    "    \"\"\"\n",
    "    Parse the activation patching data from the given string format.\n",
    "    \n",
    "    Format: common_entity | clean_entity => \" clean_answer\" | <-- | patched_entity => \" patched_answer\"\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    \n",
    "    # Split by newlines and process each line\n",
    "    lines = data_string.strip().split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        # Parse the line using regex\n",
    "        # Pattern: entity1 | entity2 => \" answer1\" | <-- | entity3 => \" answer2\"\n",
    "        pattern = r'^([^|]+)\\|([^=]+)=> \"([^\"]+)\" \\| <-- \\| ([^=]+)=> \"([^\"]+)\"'\n",
    "        match = re.match(pattern, line)\n",
    "        \n",
    "        if match:\n",
    "            common_entity = match.group(1).strip()\n",
    "            clean_entity = match.group(2).strip()\n",
    "            clean_answer = match.group(3).strip()\n",
    "            patched_entity = match.group(4).strip()\n",
    "            patched_answer = match.group(5).strip()\n",
    "\n",
    "            prompt_temp = create_prompt_template(common_entity)\n",
    "            \n",
    "            sample = ActivationPatchingSamples(\n",
    "                prompt_template=prompt_temp,\n",
    "                common_entity=common_entity,\n",
    "                clean_entity=clean_entity,\n",
    "                patched_entity=patched_entity,\n",
    "                clean_answer=clean_answer,\n",
    "                patched_answer=patched_answer,\n",
    "                patched_answer_toks=mt.tokenizer.encode(patched_answer, add_special_tokens=False)\n",
    "            )\n",
    "            samples.append(sample)\n",
    "        else:\n",
    "            print(f\"Warning: Could not parse line: {line}\")\n",
    "    \n",
    "    return samples\n",
    "\n",
    "data = f\"\"\"Grace Wanjiru | James Mwangi => \" Ken\" | <-- | Fatima Sheikh => \" Urban\"\n",
    "Rahman Ali | Nasreen Begum => \" Bang\" | <-- | Takeshi Yamamoto => \" Civil\"\n",
    "Takeshi Yamamoto | Yuki Tanaka => \" Japanese\" | <-- | Rahman Ali => \" Civil\"\n",
    "Anna Schmidt | Hans Mueller => \" German\" | <-- | Yuki Tanaka => \" Marketing\"\n",
    "Yuki Tanaka | Takeshi Yamamoto => \" Japanese\" | <-- | Anna Schmidt => \" Marketing\"\n",
    "Ayse Kaya | Maria Santos => \" Doctor\" | <-- | Hans Mueller => \" Economist\"\n",
    "Hans Mueller | Anna Schmidt => \" German\" | <-- | Ayse Kaya => \" Economist\"\n",
    "Priya Patel | Rajesh Kumar => \" Indian\" | <-- | Sofia Hernandez => \" Graphic\"\n",
    "Sofia Hernandez | Carlos Rodriguez => \" Mexican\" | <-- | Priya Patel => \" Graphic\"\n",
    "Zahra Hosseini | Ali Rezaei => \" Iranian\" | <-- | Ahmed Hassan => \" Pilot\"\n",
    "Ahmed Hassan | Layla Mahmoud => \" Egyptian\" | <-- | Zahra Hosseini => \" Pilot\"\n",
    "Kwame Mensah | Rahman Ali => \" Doctor\" | <-- | Min-jun Park => \" Ge\"\n",
    "Tran Thi Mai | Nguyen Van Duc => \" Vietnamese\" | <-- | Marco Rossi => \" Architect\"\n",
    "Marco Rossi | Giulia Romano => \" Italian\" | <-- | Tran Thi Mai => \" Architect\"\n",
    "Giulia Romano | Marco Rossi => \" Italian\" | <-- | Akosua Boateng => \" Data\"\n",
    "Alexandru Popescu | Elena Ionescu => \" Romanian\" | <-- | David Thompson => \" Environmental\"\n",
    "David Thompson | Sarah MacDonald => \" McGill\" | <-- | Alexandru Popescu => \" Environmental\"\n",
    "António Costa | Isabel Ferreira => \" Portuguese\" | <-- | Jack Wilson => \" Software\"\n",
    "Astrid Lindgren | Erik Andersson => \" Swedish\" | <-- | Lisa van der Berg => \" Web\"\n",
    "Rodrigo Gonzalez | Camila Torres => \" Chile\" | <-- | Maria dela Rosa => \" Mechanical\"\n",
    "\"\"\"\n",
    "\n",
    "# Parse the data\n",
    "samples = parse_activation_data(data)\n",
    "\n",
    "# Print parsed samples\n",
    "print(f\"Parsed {len(samples)} samples:\\n\")\n",
    "for i, sample in enumerate(samples[:5]):  # Show first 5\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  Prompt Template: {sample.prompt_template}\")\n",
    "    print(f\"  Common Entity: {sample.common_entity}\")\n",
    "    print(f\"  Clean Entity: {sample.clean_entity}\")\n",
    "    print(f\"  Clean Answer: {sample.clean_answer}\")\n",
    "    print(f\"  Patched Entity: {sample.patched_entity}\")\n",
    "    print(f\"  Patched Answer: {sample.patched_answer}\")\n",
    "    print(f\"  Patched Answer Token: {sample.patched_answer_toks}\")\n",
    "    print(f\"  String representation: {sample}\")\n",
    "    print()\n",
    "\n",
    "# Convert to JSON\n",
    "print(\"\\nJSON representation of first sample:\")\n",
    "print(samples[0].to_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grace Wanjiru | James Mwangi => \"Ken\" | <-- | Fatima Sheikh => \"Urban\"\n"
     ]
    }
   ],
   "source": [
    "print(str(samples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna Schmidt | Hans Mueller => \"German\" | <-- | Yuki Tanaka => \"Marketing\"\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 3\n",
    "sample = samples[sample_idx]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yuki Tanaka', 'Anna Schmidt') >> answer=' Japanese - they are both Japanese.'\n",
      "['68662(Marketing)']\n",
      "('Hans Mueller', 'Anna Schmidt') >> clean_answer=' German - they are both German.'\n"
     ]
    }
   ],
   "source": [
    "from src.functional import generate_with_patch\n",
    "\n",
    "mt.reset_forward()\n",
    "\n",
    "patch_prompt = sample.prompt_template.format(sample.patched_entity)\n",
    "answer = generate_with_patch(\n",
    "    mt = mt,\n",
    "    inputs = patch_prompt,\n",
    "    do_sample=False,\n",
    "    n_gen_per_prompt=1,\n",
    "    remove_prefix=True\n",
    ")[0]\n",
    "\n",
    "\n",
    "print(f\"{(sample.patched_entity, sample.common_entity)} >> {answer=}\")\n",
    "\n",
    "keywords = sample.patched_answer_toks\n",
    "print(f\"{[f'{t}({mt.tokenizer.decode(t)})' for t in keywords]}\")\n",
    "\n",
    "clean_prompt = sample.prompt_template.format(sample.clean_entity)\n",
    "clean_answer = generate_with_patch(\n",
    "    mt=mt,\n",
    "    inputs=clean_prompt,\n",
    "    do_sample=False,\n",
    "    n_gen_per_prompt=1,\n",
    "    remove_prefix=True\n",
    ")[0]\n",
    "print(f\"{(sample.clean_entity, sample.common_entity)} >> {clean_answer=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared attribute] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person Y and Person Z\n",
      "A: No - Person Y and Person Z have nothing in common.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n"
     ]
    }
   ],
   "source": [
    "from src.probing.prompt import BiAssociationPrefix\n",
    "from src.utils.experiment_utils import set_seed\n",
    "from src.probing.few_shot_examples import (\n",
    "    human_nationality,\n",
    "    human_profession,\n",
    "    human_alma_mater,\n",
    "    human_allergy,\n",
    "    human_car,\n",
    "    human_pet\n",
    ")\n",
    "\n",
    "prefix_generator_cls = BiAssociationPrefix\n",
    "\n",
    "prefix_generator = prefix_generator_cls(\n",
    "    filter_attributes=[\n",
    "        \"nationality\",\n",
    "        \"profession\",\n",
    "        \"school\"\n",
    "    ],\n",
    "    format = \"_3\"\n",
    ")\n",
    "\n",
    "set_seed(9001)\n",
    "prefix = prefix_generator.get_prefix()\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace_start_idx=245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(245, 249)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.tokens import align_patching_positions\n",
    "\n",
    "aligned_prompts = align_patching_positions(\n",
    "    mt=mt,\n",
    "    prompt_template=sample.prompt_template,\n",
    "    clean_subj=sample.clean_entity,\n",
    "    patched_subj=sample.patched_entity,\n",
    "    trace_start_marker=prefix_generator.question_marker\n",
    ")\n",
    "\n",
    "aligned_prompts[\"subj_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.common_entity='Anna Schmidt'\n",
      "common_entity_range=(250, 252)\n",
      "\" Anna Schmidt\"\n"
     ]
    }
   ],
   "source": [
    "from src.tokens import prepare_input, find_token_range\n",
    "from src.utils.typing import TokenizerOutput\n",
    "\n",
    "text = mt.tokenizer.decode(\n",
    "    aligned_prompts[\"clean_input\"][\"input_ids\"][0], skip_special_tokens=False\n",
    ")\n",
    "\n",
    "clean_inputs = prepare_input(\n",
    "    prompts=text, tokenizer=mt, add_special_tokens=False, return_offsets_mapping=True\n",
    ")\n",
    "\n",
    "assert torch.allclose(\n",
    "    clean_inputs.input_ids, aligned_prompts[\"clean_input\"][\"input_ids\"]\n",
    ")\n",
    "\n",
    "print(f\"{sample.common_entity=}\")\n",
    "\n",
    "common_entity_range = find_token_range(\n",
    "    string=text,\n",
    "    substring=sample.common_entity,\n",
    "    tokenizer=mt,\n",
    "    offset_mapping=clean_inputs.offset_mapping[0],\n",
    "    add_special_tokens=False,\n",
    ")\n",
    "\n",
    "print(f\"{common_entity_range=}\")\n",
    "\n",
    "tokenized_input = TokenizerOutput(data=aligned_prompts[\"clean_input\"])\n",
    "print(\n",
    "    f'\"{mt.tokenizer.decode(tokenized_input.input_ids[0][common_entity_range[0] : common_entity_range[1]])}\"'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.clean_entity='Hans Mueller' | \"<|eot_id|><|eot_id|> Hans Mueller\"\n",
      "sample.common_entity='Anna Schmidt' | \" Anna Schmidt\"\n",
      "sample.patched_entity='Yuki Tanaka' | \" Yuki Tanaka\n",
      "sample.common_entity='Anna Schmidt' | \" Anna Schmidt\"\n"
     ]
    }
   ],
   "source": [
    "from src.probing.utils import ProbingPrompt\n",
    "\n",
    "aligned_clean_prompt = ProbingPrompt(\n",
    "    prompt=mt.tokenizer.decode(\n",
    "        aligned_prompts[\"clean_input\"][\"input_ids\"][0], skip_special_tokens=False\n",
    "    ),\n",
    "    entities=[sample.clean_entity, sample.common_entity],\n",
    "    model_key=model_key,\n",
    "    tokenized=aligned_prompts[\"clean_input\"],\n",
    "    entity_ranges=[\n",
    "        aligned_prompts[\"subj_range\"],\n",
    "        common_entity_range,\n",
    "    ],\n",
    "    query_range=[-1, -1]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'{sample.clean_entity=} | \"{mt.tokenizer.decode(aligned_clean_prompt.tokenized.input_ids[0][aligned_prompts[\"subj_range\"][0] : aligned_prompts[\"subj_range\"][1]])}\"'\n",
    ")\n",
    "print(\n",
    "    f'{sample.common_entity=} | \"{mt.tokenizer.decode(aligned_clean_prompt.tokenized.input_ids[0][common_entity_range[0] : common_entity_range[1]])}\"'\n",
    ")\n",
    "\n",
    "aligned_patch_prompt = ProbingPrompt(\n",
    "    prompt=mt.tokenizer.decode(\n",
    "        aligned_prompts[\"patched_input\"][\"input_ids\"][0], skip_special_tokens=False\n",
    "    ),\n",
    "    entities=[sample.patched_entity, sample.common_entity],\n",
    "    model_key=model_key,\n",
    "    tokenized=aligned_prompts[\"patched_input\"],\n",
    "    entity_ranges=[\n",
    "        aligned_prompts[\"subj_range\"],\n",
    "        common_entity_range,\n",
    "    ],\n",
    "    query_range=[-1, -1],\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'{sample.patched_entity=} | \"{mt.tokenizer.decode(aligned_patch_prompt.tokenized.input_ids[0][aligned_prompts[\"subj_range\"][0] : aligned_prompts[\"subj_range\"][1]])}'\n",
    ")\n",
    "print(\n",
    "    f'{sample.common_entity=} | \"{mt.tokenizer.decode(aligned_patch_prompt.tokenized.input_ids[0][common_entity_range[0] : common_entity_range[1]])}\"'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_LAYER_WINDOW = list(range(5, 10))\n",
    "METRIC = \"logit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functional import interpret_logits, get_hs\n",
    "from src.functional import PatchSpec\n",
    "from src.trace import get_score\n",
    "from typing import Literal\n",
    "\n",
    "@torch.inference_mode()\n",
    "def patched_run(\n",
    "    mt: ModelandTokenizer,\n",
    "    inputs: TokenizerOutput,\n",
    "    patches: list[PatchSpec],\n",
    "    ans_tokens: list[int],\n",
    "    metric: Literal[\"logit\", \"prob\"] = \"logit\",\n",
    "    generate_full_ans: bool = False,\n",
    "    **next_tok_kwargs,\n",
    "):\n",
    "    if generate_full_ans:\n",
    "        answer = generate_with_patch(\n",
    "            mt=mt,\n",
    "            inputs=inputs,\n",
    "            n_gen_per_prompt=1,\n",
    "            do_sample=False,\n",
    "            patches=patches,\n",
    "            patch_strategy=\"replace\",\n",
    "            remove_prefix=True,\n",
    "            patch_at_all_generations=False\n",
    "        )\n",
    "        print(f'\"{answer[0]}\"')\n",
    "\n",
    "    logits = get_hs(\n",
    "        mt=mt,\n",
    "        input=inputs,\n",
    "        locations=[(mt.lm_head_name, -1)],\n",
    "        patches=patches,\n",
    "        return_dict=False,\n",
    "    ).squeeze()\n",
    "\n",
    "    pred, track = interpret_logits(\n",
    "        tokenizer=mt, logits=logits, interested_tokens=ans_tokens, **next_tok_kwargs\n",
    "    )\n",
    "\n",
    "    score = get_score(logits=logits, token_id=ans_tokens, metric=metric)\n",
    "\n",
    "    return score, pred, track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_score=1.5078125\n",
      "gold_pred=[PredictedToken(token=' Japanese', prob=0.37109375, logit=19.875, token_id=11002, metadata=None), PredictedToken(token=' German', prob=0.09375, logit=18.5, token_id=6063, metadata=None), PredictedToken(token=' Both', prob=0.0830078125, logit=18.375, token_id=11995, metadata=None), PredictedToken(token=' They', prob=0.0732421875, logit=18.25, token_id=2435, metadata=None), PredictedToken(token=' Same', prob=0.056884765625, logit=18.0, token_id=26823, metadata=None)]\n",
      "gold_track={68662: (62484, PredictedToken(token='Marketing', prob=3.92901711165905e-09, logit=1.5078125, token_id=68662, metadata=None))}\n",
      "corrupt_score=0.9375\n",
      "corrupt_pred=[PredictedToken(token=' German', prob=0.7109375, logit=20.5, token_id=6063, metadata=None), PredictedToken(token=' Germans', prob=0.03125, logit=17.375, token_id=42037, metadata=None), PredictedToken(token=' Hans', prob=0.027587890625, logit=17.25, token_id=25844, metadata=None), PredictedToken(token=' Both', prob=0.0244140625, logit=17.125, token_id=11995, metadata=None), PredictedToken(token=' Germany', prob=0.021484375, logit=17.0, token_id=10057, metadata=None)]\n",
      "corrupt_track={68662: (75984, PredictedToken(token='Marketing', prob=2.270098775625229e-09, logit=0.9375, token_id=68662, metadata=None))}\n",
      "layer_window=['model.layers.5', 'model.layers.6', 'model.layers.7', 'model.layers.8', 'model.layers.9']\n",
      "patches=[PatchSpec(location=('model.layers.5', 245), patch=tensor([ 0.0674,  0.0693,  0.1934,  ..., -0.0398,  0.0967,  0.0645],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.5', 246), patch=tensor([ 0.0061,  0.0469, -0.0771,  ..., -0.1230, -0.0664,  0.0630],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.5', 247), patch=tensor([-0.0186,  0.1182,  0.3359,  ..., -0.0854, -0.0820,  0.0703],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.5', 248), patch=tensor([ 0.0986,  0.0265, -0.0398,  ..., -0.1025,  0.0018,  0.1016],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.6', 245), patch=tensor([ 0.0537,  0.1074,  0.1982,  ..., -0.0146,  0.0723,  0.0032],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.6', 246), patch=tensor([-0.0427,  0.0034, -0.0776,  ...,  0.0146, -0.0320,  0.0540],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.6', 247), patch=tensor([-0.1001,  0.0781,  0.3281,  ...,  0.0552,  0.0181,  0.1123],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.6', 248), patch=tensor([ 0.0923, -0.0215, -0.0508,  ...,  0.0146,  0.0449,  0.1621],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.7', 245), patch=tensor([ 0.0640,  0.0576,  0.2109,  ..., -0.1094,  0.0425,  0.0352],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.7', 246), patch=tensor([ 0.0327, -0.0815, -0.0933,  ...,  0.0413,  0.0131,  0.0962],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.7', 247), patch=tensor([-0.0312,  0.0889,  0.3711,  ...,  0.0591, -0.0398,  0.0913],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.7', 248), patch=tensor([ 0.0742, -0.1299, -0.0718,  ...,  0.1221,  0.0574,  0.1006],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.8', 245), patch=tensor([ 0.0383,  0.0413,  0.2031,  ..., -0.1064, -0.0234,  0.0728],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.8', 246), patch=tensor([-0.0327, -0.0383, -0.1011,  ..., -0.1338,  0.0383,  0.1729],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.8', 247), patch=tensor([ 0.0586, -0.0303,  0.4512,  ..., -0.0232, -0.0237,  0.0300],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.8', 248), patch=tensor([-0.0820,  0.0425, -0.0469,  ..., -0.0400,  0.1777,  0.0674],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.9', 245), patch=tensor([-0.0591, -0.0156,  0.2090,  ...,  0.0146,  0.0201, -0.0195],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.9', 246), patch=tensor([-0.1006,  0.0244, -0.1436,  ..., -0.0674,  0.0337,  0.0547],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.9', 247), patch=tensor([-0.0187,  0.0046,  0.5938,  ..., -0.0791, -0.0869,  0.1182],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None), PatchSpec(location=('model.layers.9', 248), patch=tensor([-0.1982,  0.1182, -0.0004,  ..., -0.0132,  0.0361,  0.1216],\n",
      "       device='cuda:0', dtype=torch.bfloat16), clean=None)]\n",
      "\" Japanese - they are both Japanese.\"\n",
      "patched_score=1.125\n",
      "pred=[PredictedToken(token=' Japanese', prob=0.51953125, logit=20.375, token_id=11002, metadata=None), PredictedToken(token=' German', prob=0.1484375, logit=19.125, token_id=6063, metadata=None), PredictedToken(token=' Y', prob=0.033203125, logit=17.625, token_id=816, metadata=None), PredictedToken(token=' Same', prob=0.029296875, logit=17.5, token_id=26823, metadata=None), PredictedToken(token=' Japan', prob=0.0228271484375, logit=17.25, token_id=6457, metadata=None)]\n",
      "track={68662: (71484, PredictedToken(token='Marketing', prob=2.255546860396862e-09, logit=1.125, token_id=68662, metadata=None))}\n",
      "indirect_effect=0.3287671232876712\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from src.functional import get_hs\n",
    "from src.utils.typing import TokenizerOutput\n",
    "\n",
    "patch_states = get_hs(\n",
    "    mt=mt,\n",
    "    input=TokenizerOutput(data=aligned_prompts[\"patched_input\"]),\n",
    "    locations=list(\n",
    "        itertools.product(mt.layer_names, list(range(*aligned_prompts[\"subj_range\"])))\n",
    "    ),\n",
    "    return_dict=True\n",
    ")\n",
    "\n",
    "gold_score, gold_pred, gold_track = patched_run(\n",
    "    mt=mt,\n",
    "    inputs=TokenizerOutput(data=aligned_prompts[\"patched_input\"]),\n",
    "    patches=[],\n",
    "    ans_tokens=keywords,\n",
    "    metric=METRIC,\n",
    ")\n",
    "print(f\"{gold_score=}\")\n",
    "print(f\"{gold_pred=}\")\n",
    "print(f\"{gold_track=}\")\n",
    "\n",
    "corrupt_score, corrupt_pred, corrupt_track = patched_run(\n",
    "    mt=mt,\n",
    "    # inputs = TokenizerOutput(data = clean_prompt.tokenized),\n",
    "    inputs=TokenizerOutput(data=aligned_prompts[\"clean_input\"]),\n",
    "    patches=[],\n",
    "    ans_tokens=keywords,\n",
    "    # generate_full_ans = True,\n",
    "    metric=METRIC,\n",
    ")\n",
    "print(f\"{corrupt_score=}\")\n",
    "print(f\"{corrupt_pred=}\")\n",
    "print(f\"{corrupt_track=}\")\n",
    "\n",
    "layer_window = [mt.layer_name_format.format(l) for l in PATCH_LAYER_WINDOW]\n",
    "\n",
    "print(f\"{layer_window=}\")\n",
    "\n",
    "tokenized_input = TokenizerOutput(data=aligned_prompts[\"clean_input\"])\n",
    "\n",
    "patches = [\n",
    "    PatchSpec(location=(layer, token_idx), patch=patch_states[(layer, token_idx)])\n",
    "    for layer, token_idx in itertools.product(\n",
    "        layer_window, range(*aligned_prompts[\"subj_range\"])\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"{patches=}\")\n",
    "\n",
    "patched_score, pred, track = patched_run(\n",
    "    mt=mt,\n",
    "    inputs=tokenized_input,\n",
    "    patches=patches,\n",
    "    ans_tokens=keywords,\n",
    "    generate_full_ans=True,\n",
    "    metric=METRIC,\n",
    ")\n",
    "\n",
    "print(f\"{patched_score=}\")\n",
    "print(f\"{pred=}\")\n",
    "print(f\"{track=}\")\n",
    "\n",
    "indirect_effect = (patched_score - corrupt_score) / (gold_score - corrupt_score)\n",
    "print(f\"{indirect_effect=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' German', prob=0.7109375, logit=20.5, token_id=6063, metadata=None),\n",
       "  PredictedToken(token=' Germans', prob=0.03125, logit=17.375, token_id=42037, metadata=None),\n",
       "  PredictedToken(token=' Hans', prob=0.027587890625, logit=17.25, token_id=25844, metadata=None),\n",
       "  PredictedToken(token=' Both', prob=0.0244140625, logit=17.125, token_id=11995, metadata=None),\n",
       "  PredictedToken(token=' Germany', prob=0.021484375, logit=17.0, token_id=10057, metadata=None)]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt = mt,\n",
    "    inputs  =TokenizerOutput(data=aligned_prompts[\"clean_input\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 257])\n",
      "output.keys(: odict_keys(['last_hidden_state', 'past_key_values', 'attentions'])\n",
      "logits.shape: torch.Size([128256])\n",
      "score=1.5703125\n",
      "indirect_effect=1.1095890410958904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([PredictedToken(token=' Japanese', prob=0.42578125, logit=20.0, token_id=11002, metadata=None),\n",
       "  PredictedToken(token=' German', prob=0.083984375, logit=18.375, token_id=6063, metadata=None),\n",
       "  PredictedToken(token=' Both', prob=0.07421875, logit=18.25, token_id=11995, metadata=None),\n",
       "  PredictedToken(token=' They', prob=0.0576171875, logit=18.0, token_id=2435, metadata=None),\n",
       "  PredictedToken(token=' Same', prob=0.051025390625, logit=17.875, token_id=26823, metadata=None)],\n",
       " {68662: (59095,\n",
       "   PredictedToken(token='Marketing', prob=4.220055416226387e-09, logit=1.5703125, token_id=68662, metadata=None))})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.attention import get_attention_matrices\n",
    "\n",
    "tokenized_input = TokenizerOutput(data=aligned_prompts[\"patched_input\"])\n",
    "\n",
    "print(tokenized_input.input_ids.shape)\n",
    "\n",
    "attn_output = get_attention_matrices(\n",
    "    input = tokenized_input,\n",
    "    mt = mt,\n",
    ")\n",
    "\n",
    "score = get_score(\n",
    "    logits = attn_output.logits,\n",
    "    token_id = keywords,\n",
    "    metric = METRIC\n",
    ")\n",
    "\n",
    "print(f\"{score=}\")\n",
    "\n",
    "indirect_effect = (score - corrupt_score) / (gold_score - corrupt_score)\n",
    "print(f\"{indirect_effect=}\")\n",
    "\n",
    "interpret_logits(logits = attn_output.logits, tokenizer=mt, interested_tokens=keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-ed74ca3e-7c8a\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-ed74ca3e-7c8a\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\" Y\", \"uki\", \" Tan\", \"aka\", \" and\", \" Anna\", \" Schmidt\", \"\\n\", \"A\", \":\", \" Yes\", \" -\"], \"values\": [0.015517146326601505, 0.0065816231071949005, 0.0036466200836002827, 0.002812410006299615, 0.029751526191830635, 0.0066949124448001385, 0.00222399621270597, 0.07354968786239624, 0.02811150997877121, 0.039740223437547684, 0.042416103184223175, 0.029238849878311157]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f9729f2cdc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "layer=6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-8ab4e767-aa9c\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-8ab4e767-aa9c\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\" Y\", \"uki\", \" Tan\", \"aka\", \" and\", \" Anna\", \" Schmidt\", \"\\n\", \"A\", \":\", \" Yes\", \" -\"], \"values\": [0.008458033204078674, 0.011751840822398663, 0.003758651204407215, 0.009683283977210522, 0.041651301085948944, 0.012349465861916542, 0.014783035963773727, 0.06962186098098755, 0.01726943999528885, 0.03426468372344971, 0.0636235922574997, 0.07178306579589844]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f96bc5ddf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "layer=7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-a25d2adb-e0c0\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-a25d2adb-e0c0\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\" Y\", \"uki\", \" Tan\", \"aka\", \" and\", \" Anna\", \" Schmidt\", \"\\n\", \"A\", \":\", \" Yes\", \" -\"], \"values\": [0.009964004158973694, 0.013012796640396118, 0.003855193266645074, 0.008483676239848137, 0.025068387389183044, 0.008028797805309296, 0.008969591930508614, 0.05512314289808273, 0.013717802241444588, 0.026682639494538307, 0.03186139464378357, 0.048072874546051025]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f9729f2c760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "layer=8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-996b609c-7319\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-996b609c-7319\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\" Y\", \"uki\", \" Tan\", \"aka\", \" and\", \" Anna\", \" Schmidt\", \"\\n\", \"A\", \":\", \" Yes\", \" -\"], \"values\": [0.006086763460189104, 0.015420801006257534, 0.004706467501819134, 0.011214138939976692, 0.03026370331645012, 0.02044035866856575, 0.025221114978194237, 0.04314035922288895, 0.005957933142781258, 0.015622359700500965, 0.0419500358402729, 0.05690740421414375]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f96bc5dee90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "layer=9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-5263fc56-0a7f\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-5263fc56-0a7f\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\" Y\", \"uki\", \" Tan\", \"aka\", \" and\", \" Anna\", \" Schmidt\", \"\\n\", \"A\", \":\", \" Yes\", \" -\"], \"values\": [0.011806610971689224, 0.028410974889993668, 0.005909040570259094, 0.022131239995360374, 0.01315217837691307, 0.01943206787109375, 0.037545040249824524, 0.011910369619727135, 0.0030471747741103172, 0.018386729061603546, 0.04744328558444977, 0.08158761262893677]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f9729f2ce50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "layer=10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-6fec7efa-8b88\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-6fec7efa-8b88\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\" Y\", \"uki\", \" Tan\", \"aka\", \" and\", \" Anna\", \" Schmidt\", \"\\n\", \"A\", \":\", \" Yes\", \" -\"], \"values\": [0.008989676833152771, 0.021608076989650726, 0.0030208260286599398, 0.020109636709094048, 0.011241928674280643, 0.014083463698625565, 0.020471854135394096, 0.007217552978545427, 0.0023733603302389383, 0.012226307764649391, 0.016284696757793427, 0.07893569767475128]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f96bc5ddf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "layer=11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-460983a3-8402\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-460983a3-8402\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\" Y\", \"uki\", \" Tan\", \"aka\", \" and\", \" Anna\", \" Schmidt\", \"\\n\", \"A\", \":\", \" Yes\", \" -\"], \"values\": [0.0051279086619615555, 0.032885849475860596, 0.0018149390816688538, 0.02990211546421051, 0.021464422345161438, 0.012286949902772903, 0.02367401495575905, 0.002400461118668318, 0.0010061125503852963, 0.007833360694348812, 0.024417929351329803, 0.05072444677352905]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f9729f2cdc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "layer=12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-6b5e63d4-93ed\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-6b5e63d4-93ed\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\" Y\", \"uki\", \" Tan\", \"aka\", \" and\", \" Anna\", \" Schmidt\", \"\\n\", \"A\", \":\", \" Yes\", \" -\"], \"values\": [0.004548788070678711, 0.016705848276615143, 0.005633130669593811, 0.010976582765579224, 0.0029669683426618576, 0.007626265287399292, 0.006349503993988037, 0.001895054941996932, 0.001921547343954444, 0.008427056483924389, 0.019977161660790443, 0.06361603736877441]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f96bc5dee90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "layer=13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-7295d55b-32ed\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-7295d55b-32ed\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\" Y\", \"uki\", \" Tan\", \"aka\", \" and\", \" Anna\", \" Schmidt\", \"\\n\", \"A\", \":\", \" Yes\", \" -\"], \"values\": [0.003969050943851471, 0.029288670048117638, 0.005530945956707001, 0.03261739760637283, 0.006052851676940918, 0.007277652621269226, 0.007619778160005808, 0.0011271797120571136, 0.00044362759217619896, 0.00475117564201355, 0.016291962936520576, 0.06550902128219604]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f9729f2c760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.attention import visualize_average_attn_matrix\n",
    "\n",
    "visualize_average_attn_matrix(\n",
    "    mt = mt,\n",
    "    attn_matrices = attn_output,\n",
    "    prompt=aligned_patch_prompt,\n",
    "    layer_window=range(5, 14),\n",
    "    q_index=-1,\n",
    "    remove_bos=True,\n",
    "    start_from = aligned_prompts[\"subj_range\"][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patching while ablating heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTN_LAYER_WINDOW = list(range(30, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = TokenizerOutput(data=aligned_prompts[\"clean_input\"])\n",
    "\n",
    "start_idx = aligned_prompts[\"trace_start_idx\"]\n",
    "context_range = list(range(0, start_idx + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocking attention to the subject tokens\n",
    "import baukit\n",
    "\n",
    "mt.reset_forward()\n",
    "\n",
    "focus_edges_on = get_edges_to_be_ablated(\n",
    "    prompt=aligned_clean_prompt,\n",
    "    focus_strategy=\"entities\",\n",
    "    Q_IDX=-1,\n",
    "    whitelist_key_indices=context_range + [-1],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
