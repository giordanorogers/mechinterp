{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 17:57:30 __main__ INFO     torch.__version__='2.5.1+cu121', torch.version.cuda='12.1'\n",
      "2025-06-25 17:57:30 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=1, torch.cuda.get_device_name()='NVIDIA RTX A6000'\n",
      "2025-06-25 17:57:30 __main__ INFO     transformers.__version__='4.52.4'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 17:57:30 src.utils.training_utils WARNING   Model meta-llama/Llama-3.2-1B-Instruct not supported  Only 1 GPU(s) available using default device map = `auto`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'auto'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "model_key = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "device_map = get_device_map(model_key, 32, 1)\n",
    "device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 17:57:33 src.models WARNING  meta-llama/Llama-3.2-1B-Instruct not found in data/hf_cache\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-06-25 17:57:33 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-06-25 17:57:34 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-06-25 17:57:34 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-1B-Instruct/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-06-25 17:57:34 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/models/meta-llama/Llama-3.2-1B-Instruct/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "2025-06-25 17:57:34 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "2025-06-25 17:57:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-1B-Instruct/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "2025-06-25 17:57:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-1B-Instruct/resolve/main/custom_generate/generate.py HTTP/1.1\" 404 0\n",
      "2025-06-25 17:57:35 src.models INFO     loaded model <meta-llama/Llama-3.2-1B-Instruct> | size: 2357.129 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from typing import Literal\n",
    "#from src.probing.prompt import ProbingPrompt\n",
    "#from src.hooking.llama_attention import AttentionEdge\n",
    "#\n",
    "#def get_edges_to_be_ablated(\n",
    "#    prompt: ProbingPrompt,\n",
    "#    focus_strategy: Literal[\"entities\", \"entities_last\", \"ablate_all\"] = \"ablate_all\",\n",
    "#    Q_IDX: int = -1, # almost always the last token position\n",
    "#    whitelist_key_indices: list[int] = [0, -1],\n",
    "#):\n",
    "#    \"\"\"\n",
    "#    For attention ablation experiments.\n",
    "#    Determines which attention connections should be blocked (ablated) between tokens.\n",
    "#    Used to understand which attention patterns are important for specific model behaviors.\n",
    "#\n",
    "#    Creates a block list of attention edges by:\n",
    "#        1. Converting negative indices to positive ones\n",
    "#        2. Building a whitelist of key positions to preserve based on the strategy\n",
    "#        3. Creating AttentionEdge objects for all non-whitelisted positions\n",
    "#\n",
    "#    Whitelisting strategy: Instead of specifying which edge to ablate, specify which connections\n",
    "#        to preserve, and everything else gets ablated.\n",
    "#\n",
    "#    Arguments:\n",
    "#        focus_strategy: controls which entity-related tokens to preserve\n",
    "#            entities: keeps all tokens within both entity ranges\n",
    "#            entities_last: only keeps the last token of each entity\n",
    "#            ablate_all: no special entity preservation\n",
    "#        Q_IDX: the query token position (usually the last token where we want to measure the effect)\n",
    "#        whitelist_key_indices: additional key positions to preserve (defaults to first and last tokens)\n",
    "#\n",
    "#    Returns:\n",
    "#        AttentionEdge: represent specific attention connections from a query token position\n",
    "#            to key token positions that should be blocked.\n",
    "#    \"\"\"\n",
    "#    for idx, ti in enumerate(whitelist_key_indices):\n",
    "#        if ti < 0:\n",
    "#            whitelist_key_indices[idx] = prompt.tokenized[\"input_ids\"][0].shape[-1] + ti\n",
    "#    \n",
    "#    if focus_strategy == \"entities\":\n",
    "#        whitelist_key_indices += list(range(*prompt.entity_ranges[0])) + list(\n",
    "#            range(*prompt.entity_ranges[1])\n",
    "#        )\n",
    "#    elif focus_strategy == \"entities_last\":\n",
    "#        whitelist_key_indices += [\n",
    "#            prompt.entity_ranges[0][1] - 1,\n",
    "#            prompt.entity_ranges[1][1] - 1,\n",
    "#        ]\n",
    "#    elif focus_strategy == \"ablate_all\":\n",
    "#        pass\n",
    "#    else:\n",
    "#        raise ValueError(f\"{focus_strategy=}\")\n",
    "#\n",
    "#    whitelist_key_indices = list(set(whitelist_key_indices))\n",
    "#    if Q_IDX < 0:\n",
    "#        Q_IDX = prompt.tokenized[\"input_ids\"][0].shape[-1] + Q_IDX\n",
    "#\n",
    "#    block_edges: list[AttentionEdge] = []\n",
    "#    for k_idx in range(0, prompt.tokenized[\"input_ids\"][0].shape[-1]):\n",
    "#        if k_idx in whitelist_key_indices:\n",
    "#            continue\n",
    "#        block_edges.append(\n",
    "#            AttentionEdge(\n",
    "#                q_idx=Q_IDX,\n",
    "#                k_idx=k_idx,\n",
    "#            )\n",
    "#        )\n",
    "#\n",
    "#    return block_edges\n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(os.path.join(env_utils.DEFAULT_DATA_DIR, \"coincidences_sample.json\")) as f:\n",
    "#    coincidences = json.load(f)\n",
    "#\n",
    "#logger.info(f\"{len(coincidences['examples'])=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from typing import Literal\n",
    "#from src.probing.prompt import prepare_probing_input\n",
    "#from src.functional import predict_next_token\n",
    "#from src.tokens import TokenizerOutput\n",
    "#\n",
    "#focus_strategy: Literal[\"entities\", \"entities_last\", \"ablate_all\"] = \"entities\"\n",
    "#\n",
    "#effects = []\n",
    "#\n",
    "#for idx, c in enumerate(coincidences[\"examples\"]):\n",
    "#    entities = c[\"entity_pair\"]\n",
    "#    logger.info(f\"({idx + 1}/{len(coincidences['examples'])})  {entities=}\")\n",
    "#\n",
    "#    prompt = prepare_probing_input(\n",
    "#        mt=mt,\n",
    "#        entities=entities,\n",
    "#        #prefix=prefix,\n",
    "#        #answer_marker=answer_marker,\n",
    "#        #question_marker=question_marker,\n",
    "#        #block_separator=block_separator,\n",
    "#        answer_prefix=\" They are/were both\",\n",
    "#    )\n",
    "#\n",
    "#    logger.info(f\"{prompt=}\")\n",
    "#\n",
    "#    clean_answer = predict_next_token(\n",
    "#        mt=mt, inputs=TokenizerOutput(data=prompt.tokenized), topK=1\n",
    "#    )[0][0]\n",
    "#    logger.info(f\"{clean_answer=}\")\n",
    "#\n",
    "#    block_edges = get_edges_to_be_ablated(\n",
    "#        prompt=prompt,\n",
    "#        focus_strategy=focus_strategy,\n",
    "#        Q_IDX=-2,\n",
    "#        whitelist_key_indices=[0]\n",
    "#    )\n",
    "#\n",
    "#    logger.info(f\"{block_edges=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patching from a different run to check contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.probing.prompt import BiAssociationPrefix\n",
    "#from src.utils.experiment_utils import set_seed\n",
    "#\n",
    "#prefix_generator_cls = BiAssociationPrefix\n",
    "#\n",
    "#set_seed(9001)\n",
    "#\n",
    "#prefix_generator = prefix_generator_cls(\n",
    "#    filter_attributes=[\"nationality\", \"profession\", \"school\"],\n",
    "#    format=\"_3\"\n",
    "#)\n",
    "#\n",
    "#prefix = prefix_generator.get_prefix(\n",
    "#    n_valid=10,\n",
    "#    n_none=1\n",
    "#)\n",
    "#print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 42\n",
      "y: hello\n",
      "# Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared attribute] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person Y and Person Z\n",
      "A: No - Person Y and Person Z have nothing in common.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n"
     ]
    }
   ],
   "source": [
    "from src.probing.prompt import BiAssociationPrefix\n",
    "from src.utils.experiment_utils import set_seed\n",
    "from src.probing.few_shot_examples import (\n",
    "    human_nationality,\n",
    "    human_profession,\n",
    "    human_alma_mater\n",
    ")\n",
    "\n",
    "prefix_generator_cls = BiAssociationPrefix\n",
    "\n",
    "prefix_generator = prefix_generator_cls(\n",
    "    filter_attributes=[\n",
    "        \"nationality\",\n",
    "        \"profession\",\n",
    "        \"school\"\n",
    "    ],\n",
    "    format = \"_3\"\n",
    ")\n",
    "\n",
    "set_seed(9001)\n",
    "prefix = prefix_generator.get_prefix()\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.tokens import align_patching_positions, find_token_range\n",
    "#\n",
    "#aligned_prompts = align_patching_positions(\n",
    "#    mt=mt,\n",
    "#    prompt_template=sample.prompt_template,\n",
    "#    clean_subj=sample.clean_entity,\n",
    "#    patched_subj=sample.patched_entity,\n",
    "#    trace_start_marker=prefix_generator.question_marker,\n",
    "#)\n",
    "#\n",
    "#aligned_prompts[\"subj_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 20 samples:\n",
      "\n",
      "Sample 1:\n",
      "  Prompt Template: # Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n",
      "\n",
      "Q: {} and Grace Wanjiru\n",
      "A: Yes -\n",
      "  Common Entity: Grace Wanjiru\n",
      "  Clean Entity: James Mwangi\n",
      "  Clean Answer: Ken\n",
      "  Patched Entity: Fatima Sheikh\n",
      "  Patched Answer: Urban\n",
      "  Patched Answer Token: [94368]\n",
      "  String representation: Grace Wanjiru | James Mwangi => \"Ken\" | <-- | Fatima Sheikh => \"Urban\"\n",
      "\n",
      "Sample 2:\n",
      "  Prompt Template: # Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n",
      "\n",
      "Q: {} and Rahman Ali\n",
      "A: Yes -\n",
      "  Common Entity: Rahman Ali\n",
      "  Clean Entity: Nasreen Begum\n",
      "  Clean Answer: Bang\n",
      "  Patched Entity: Takeshi Yamamoto\n",
      "  Patched Answer: Civil\n",
      "  Patched Answer Token: [68926]\n",
      "  String representation: Rahman Ali | Nasreen Begum => \"Bang\" | <-- | Takeshi Yamamoto => \"Civil\"\n",
      "\n",
      "Sample 3:\n",
      "  Prompt Template: # Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n",
      "\n",
      "Q: {} and Takeshi Yamamoto\n",
      "A: Yes -\n",
      "  Common Entity: Takeshi Yamamoto\n",
      "  Clean Entity: Yuki Tanaka\n",
      "  Clean Answer: Japanese\n",
      "  Patched Entity: Rahman Ali\n",
      "  Patched Answer: Civil\n",
      "  Patched Answer Token: [68926]\n",
      "  String representation: Takeshi Yamamoto | Yuki Tanaka => \"Japanese\" | <-- | Rahman Ali => \"Civil\"\n",
      "\n",
      "Sample 4:\n",
      "  Prompt Template: # Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n",
      "\n",
      "Q: {} and Anna Schmidt\n",
      "A: Yes -\n",
      "  Common Entity: Anna Schmidt\n",
      "  Clean Entity: Hans Mueller\n",
      "  Clean Answer: German\n",
      "  Patched Entity: Yuki Tanaka\n",
      "  Patched Answer: Marketing\n",
      "  Patched Answer Token: [68662]\n",
      "  String representation: Anna Schmidt | Hans Mueller => \"German\" | <-- | Yuki Tanaka => \"Marketing\"\n",
      "\n",
      "Sample 5:\n",
      "  Prompt Template: # Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n",
      "\n",
      "Q: {} and Yuki Tanaka\n",
      "A: Yes -\n",
      "  Common Entity: Yuki Tanaka\n",
      "  Clean Entity: Takeshi Yamamoto\n",
      "  Clean Answer: Japanese\n",
      "  Patched Entity: Anna Schmidt\n",
      "  Patched Answer: Marketing\n",
      "  Patched Answer Token: [68662]\n",
      "  String representation: Yuki Tanaka | Takeshi Yamamoto => \"Japanese\" | <-- | Anna Schmidt => \"Marketing\"\n",
      "\n",
      "\n",
      "JSON representation of first sample:\n",
      "{\n",
      "  \"prompt_template\": \"# Task: Find Common Attributes Between Two People\\nYou will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\\n\\n## Response Format:\\n- If you find a match: \\\"Yes - [shared entity] - [description of what they share]\\\"\\n- If no match: \\\"No - [Person 1] and [Person 2] have nothing in common\\\"\\n\\n## Attributes to Consider:\\n1. Same nationality \\u2192 \\\"Yes - [nationality] - they are both [nationality]\\\"\\n2. Same profession \\u2192 \\\"Yes - [profession] - they are both [profession]\\\"\\n3. Same school \\u2192 \\\"Yes - [school] - they both graduated from [school]\\\"\\n\\nQ: Person W and Person X\\nA: No - Person W and Person X have nothing in common.\\n\\nQ: Person E and Person F\\nA: Yes - Boston University - they both graduated from Boston University.\\n\\nQ: Person C and Person D\\nA: Yes - Doctor - they are both doctors.\\n\\nQ: Person A and Person B\\nA: Yes - German - they are both German.\\n\\n## Your turn, give your answer in a single line.\\n\\nQ: {} and Grace Wanjiru\\nA: Yes -\",\n",
      "  \"common_entity\": \"Grace Wanjiru\",\n",
      "  \"clean_entity\": \"James Mwangi\",\n",
      "  \"patched_entity\": \"Fatima Sheikh\",\n",
      "  \"clean_answer\": \"Ken\",\n",
      "  \"patched_answer\": \"Urban\",\n",
      "  \"patched_answer_toks\": [\n",
      "    94368\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import Optional, List\n",
    "from src.dataset import ActivationPatchingSamples\n",
    "\n",
    "def create_prompt_template(common_entity: str) -> str:\n",
    "    \"\"\"\n",
    "    Create the prompt template with the common entity inserted.\n",
    "    \"\"\"\n",
    "    template = f\"\"\"# Task: Find Common Attributes Between Two People\n",
    "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
    "\n",
    "## Response Format:\n",
    "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
    "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
    "\n",
    "## Attributes to Consider:\n",
    "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
    "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
    "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
    "\n",
    "Q: Person W and Person X\n",
    "A: No - Person W and Person X have nothing in common.\n",
    "\n",
    "Q: Person E and Person F\n",
    "A: Yes - Boston University - they both graduated from Boston University.\n",
    "\n",
    "Q: Person C and Person D\n",
    "A: Yes - Doctor - they are both doctors.\n",
    "\n",
    "Q: Person A and Person B\n",
    "A: Yes - German - they are both German.\n",
    "\n",
    "## Your turn, give your answer in a single line.\n",
    "\n",
    "Q: {{}} and {common_entity}\n",
    "A: Yes -\"\"\"\n",
    "    \n",
    "    return template\n",
    "\n",
    "def parse_activation_data(data_string: str) -> List[ActivationPatchingSamples]:\n",
    "    \"\"\"\n",
    "    Parse the activation patching data from the given string format.\n",
    "    \n",
    "    Format: common_entity | clean_entity => \" clean_answer\" | <-- | patched_entity => \" patched_answer\"\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    \n",
    "    # Split by newlines and process each line\n",
    "    lines = data_string.strip().split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        # Parse the line using regex\n",
    "        # Pattern: entity1 | entity2 => \" answer1\" | <-- | entity3 => \" answer2\"\n",
    "        pattern = r'^([^|]+)\\|([^=]+)=> \"([^\"]+)\" \\| <-- \\| ([^=]+)=> \"([^\"]+)\"'\n",
    "        match = re.match(pattern, line)\n",
    "        \n",
    "        if match:\n",
    "            common_entity = match.group(1).strip()\n",
    "            clean_entity = match.group(2).strip()\n",
    "            clean_answer = match.group(3).strip()\n",
    "            patched_entity = match.group(4).strip()\n",
    "            patched_answer = match.group(5).strip()\n",
    "\n",
    "            prompt_temp = create_prompt_template(common_entity)\n",
    "            \n",
    "            sample = ActivationPatchingSamples(\n",
    "                prompt_template=prompt_temp,\n",
    "                common_entity=common_entity,\n",
    "                clean_entity=clean_entity,\n",
    "                patched_entity=patched_entity,\n",
    "                clean_answer=clean_answer,\n",
    "                patched_answer=patched_answer,\n",
    "                patched_answer_toks=mt.tokenizer.encode(patched_answer, add_special_tokens=False)\n",
    "            )\n",
    "            samples.append(sample)\n",
    "        else:\n",
    "            print(f\"Warning: Could not parse line: {line}\")\n",
    "    \n",
    "    return samples\n",
    "\n",
    "data = f\"\"\"Grace Wanjiru | James Mwangi => \" Ken\" | <-- | Fatima Sheikh => \" Urban\"\n",
    "Rahman Ali | Nasreen Begum => \" Bang\" | <-- | Takeshi Yamamoto => \" Civil\"\n",
    "Takeshi Yamamoto | Yuki Tanaka => \" Japanese\" | <-- | Rahman Ali => \" Civil\"\n",
    "Anna Schmidt | Hans Mueller => \" German\" | <-- | Yuki Tanaka => \" Marketing\"\n",
    "Yuki Tanaka | Takeshi Yamamoto => \" Japanese\" | <-- | Anna Schmidt => \" Marketing\"\n",
    "Ayse Kaya | Maria Santos => \" Doctor\" | <-- | Hans Mueller => \" Economist\"\n",
    "Hans Mueller | Anna Schmidt => \" German\" | <-- | Ayse Kaya => \" Economist\"\n",
    "Priya Patel | Rajesh Kumar => \" Indian\" | <-- | Sofia Hernandez => \" Graphic\"\n",
    "Sofia Hernandez | Carlos Rodriguez => \" Mexican\" | <-- | Priya Patel => \" Graphic\"\n",
    "Zahra Hosseini | Ali Rezaei => \" Iranian\" | <-- | Ahmed Hassan => \" Pilot\"\n",
    "Ahmed Hassan | Layla Mahmoud => \" Egyptian\" | <-- | Zahra Hosseini => \" Pilot\"\n",
    "Kwame Mensah | Rahman Ali => \" Doctor\" | <-- | Min-jun Park => \" Ge\"\n",
    "Tran Thi Mai | Nguyen Van Duc => \" Vietnamese\" | <-- | Marco Rossi => \" Architect\"\n",
    "Marco Rossi | Giulia Romano => \" Italian\" | <-- | Tran Thi Mai => \" Architect\"\n",
    "Giulia Romano | Marco Rossi => \" Italian\" | <-- | Akosua Boateng => \" Data\"\n",
    "Alexandru Popescu | Elena Ionescu => \" Romanian\" | <-- | David Thompson => \" Environmental\"\n",
    "David Thompson | Sarah MacDonald => \" McGill\" | <-- | Alexandru Popescu => \" Environmental\"\n",
    "António Costa | Isabel Ferreira => \" Portuguese\" | <-- | Jack Wilson => \" Software\"\n",
    "Astrid Lindgren | Erik Andersson => \" Swedish\" | <-- | Lisa van der Berg => \" Web\"\n",
    "Rodrigo Gonzalez | Camila Torres => \" Chile\" | <-- | Maria dela Rosa => \" Mechanical\"\n",
    "\"\"\"\n",
    "\n",
    "# Parse the data\n",
    "samples = parse_activation_data(data)\n",
    "\n",
    "# Print parsed samples\n",
    "print(f\"Parsed {len(samples)} samples:\\n\")\n",
    "for i, sample in enumerate(samples[:5]):  # Show first 5\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  Prompt Template: {sample.prompt_template}\")\n",
    "    print(f\"  Common Entity: {sample.common_entity}\")\n",
    "    print(f\"  Clean Entity: {sample.clean_entity}\")\n",
    "    print(f\"  Clean Answer: {sample.clean_answer}\")\n",
    "    print(f\"  Patched Entity: {sample.patched_entity}\")\n",
    "    print(f\"  Patched Answer: {sample.patched_answer}\")\n",
    "    print(f\"  Patched Answer Token: {sample.patched_answer_toks}\")\n",
    "    print(f\"  String representation: {sample}\")\n",
    "    print()\n",
    "\n",
    "# Convert to JSON\n",
    "print(\"\\nJSON representation of first sample:\")\n",
    "print(samples[0].to_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grace Wanjiru | James Mwangi => \"Ken\" | <-- | Fatima Sheikh => \"Urban\"\n"
     ]
    }
   ],
   "source": [
    "print(str(samples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna Schmidt | Hans Mueller => \"German\" | <-- | Yuki Tanaka => \"Marketing\"\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 3\n",
    "sample = samples[sample_idx]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yuki Tanaka', 'Anna Schmidt') >> answer=' Japanese - they are both Japanese.'\n",
      "['68662(Marketing)']\n",
      "('Hans Mueller', 'Anna Schmidt') >> clean_answer=' German - they are both German.'\n"
     ]
    }
   ],
   "source": [
    "from src.functional import generate_with_patch\n",
    "\n",
    "mt.reset_forward()\n",
    "\n",
    "patch_prompt = sample.prompt_template.format(sample.patched_entity)\n",
    "answer = generate_with_patch(\n",
    "    mt = mt,\n",
    "    inputs = patch_prompt,\n",
    "    do_sample=False,\n",
    "    n_gen_per_prompt=1,\n",
    "    remove_prefix=True\n",
    ")[0]\n",
    "\n",
    "\n",
    "print(f\"{(sample.patched_entity, sample.common_entity)} >> {answer=}\")\n",
    "\n",
    "keywords = sample.patched_answer_toks\n",
    "print(f\"{[f'{t}({mt.tokenizer.decode(t)})' for t in keywords]}\")\n",
    "\n",
    "clean_prompt = sample.prompt_template.format(sample.clean_entity)\n",
    "clean_answer = generate_with_patch(\n",
    "    mt=mt,\n",
    "    inputs=clean_prompt,\n",
    "    do_sample=False,\n",
    "    n_gen_per_prompt=1,\n",
    "    remove_prefix=True\n",
    ")[0]\n",
    "print(f\"{(sample.clean_entity, sample.common_entity)} >> {clean_answer=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared attribute] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "2. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person Y and Person Z\n",
      "A: No - Person Y and Person Z have nothing in common.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n"
     ]
    }
   ],
   "source": [
    "from src.probing.prompt import BiAssociationPrefix\n",
    "from src.utils.experiment_utils import set_seed\n",
    "from src.probing.few_shot_examples import (\n",
    "    human_nationality,\n",
    "    human_profession,\n",
    "    human_alma_mater,\n",
    "    human_allergy,\n",
    "    human_car,\n",
    "    human_pet\n",
    ")\n",
    "\n",
    "prefix_generator_cls = BiAssociationPrefix\n",
    "\n",
    "prefix_generator = prefix_generator_cls(\n",
    "    filter_attributes=[\n",
    "        \"nationality\",\n",
    "        \"profession\",\n",
    "        \"school\"\n",
    "    ],\n",
    "    format = \"_3\"\n",
    ")\n",
    "\n",
    "set_seed(9001)\n",
    "prefix = prefix_generator.get_prefix()\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace_start_idx=245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(245, 249)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.tokens import align_patching_positions\n",
    "\n",
    "aligned_prompts = align_patching_positions(\n",
    "    mt=mt,\n",
    "    prompt_template=sample.prompt_template,\n",
    "    clean_subj=sample.clean_entity,\n",
    "    patched_subj=sample.patched_entity,\n",
    "    trace_start_marker=prefix_generator.question_marker\n",
    ")\n",
    "\n",
    "aligned_prompts[\"subj_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.common_entity='Anna Schmidt'\n",
      "common_entity_range=(250, 252)\n",
      "\" Anna Schmidt\"\n"
     ]
    }
   ],
   "source": [
    "from src.tokens import prepare_input, find_token_range\n",
    "from src.utils.typing import TokenizerOutput\n",
    "\n",
    "text = mt.tokenizer.decode(\n",
    "    aligned_prompts[\"clean_input\"][\"input_ids\"][0], skip_special_tokens=False\n",
    ")\n",
    "\n",
    "clean_inputs = prepare_input(\n",
    "    prompts=text, tokenizer=mt, add_special_tokens=False, return_offsets_mapping=True\n",
    ")\n",
    "\n",
    "assert torch.allclose(\n",
    "    clean_inputs.input_ids, aligned_prompts[\"clean_input\"][\"input_ids\"]\n",
    ")\n",
    "\n",
    "print(f\"{sample.common_entity=}\")\n",
    "\n",
    "common_entity_range = find_token_range(\n",
    "    string=text,\n",
    "    substring=sample.common_entity,\n",
    "    tokenizer=mt,\n",
    "    offset_mapping=clean_inputs.offset_mapping[0],\n",
    "    add_special_tokens=False,\n",
    ")\n",
    "\n",
    "print(f\"{common_entity_range=}\")\n",
    "\n",
    "tokenized_input = TokenizerOutput(data=aligned_prompts[\"clean_input\"])\n",
    "print(\n",
    "    f'\"{mt.tokenizer.decode(tokenized_input.input_ids[0][common_entity_range[0] : common_entity_range[1]])}\"'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.clean_entity='Hans Mueller' | \"<|eot_id|><|eot_id|> Hans Mueller\"\n",
      "sample.common_entity='Anna Schmidt' | \" Anna Schmidt\"\n",
      "sample.patched_entity='Yuki Tanaka' | \" Yuki Tanaka\n",
      "sample.common_entity='Anna Schmidt' | \" Anna Schmidt\"\n"
     ]
    }
   ],
   "source": [
    "from src.probing.utils import ProbingPrompt\n",
    "\n",
    "aligned_clean_prompt = ProbingPrompt(\n",
    "    prompt=mt.tokenizer.decode(\n",
    "        aligned_prompts[\"clean_input\"][\"input_ids\"][0], skip_special_tokens=False\n",
    "    ),\n",
    "    entities=[sample.clean_entity, sample.common_entity],\n",
    "    model_key=model_key,\n",
    "    tokenized=aligned_prompts[\"clean_input\"],\n",
    "    entity_ranges=[\n",
    "        aligned_prompts[\"subj_range\"],\n",
    "        common_entity_range,\n",
    "    ],\n",
    "    query_range=[-1, -1]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'{sample.clean_entity=} | \"{mt.tokenizer.decode(aligned_clean_prompt.tokenized.input_ids[0][aligned_prompts[\"subj_range\"][0] : aligned_prompts[\"subj_range\"][1]])}\"'\n",
    ")\n",
    "print(\n",
    "    f'{sample.common_entity=} | \"{mt.tokenizer.decode(aligned_clean_prompt.tokenized.input_ids[0][common_entity_range[0] : common_entity_range[1]])}\"'\n",
    ")\n",
    "\n",
    "aligned_patch_prompt = ProbingPrompt(\n",
    "    prompt=mt.tokenizer.decode(\n",
    "        aligned_prompts[\"patched_input\"][\"input_ids\"][0], skip_special_tokens=False\n",
    "    ),\n",
    "    entities=[sample.patched_entity, sample.common_entity],\n",
    "    model_key=model_key,\n",
    "    tokenized=aligned_prompts[\"patched_input\"],\n",
    "    entity_ranges=[\n",
    "        aligned_prompts[\"subj_range\"],\n",
    "        common_entity_range,\n",
    "    ],\n",
    "    query_range=[-1, -1],\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'{sample.patched_entity=} | \"{mt.tokenizer.decode(aligned_patch_prompt.tokenized.input_ids[0][aligned_prompts[\"subj_range\"][0] : aligned_prompts[\"subj_range\"][1]])}'\n",
    ")\n",
    "print(\n",
    "    f'{sample.common_entity=} | \"{mt.tokenizer.decode(aligned_patch_prompt.tokenized.input_ids[0][common_entity_range[0] : common_entity_range[1]])}\"'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
